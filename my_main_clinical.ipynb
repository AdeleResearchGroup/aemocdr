{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76df4ad-00cd-4f5a-aa90-74b4b380890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from DeepDRA_clinical import DeepDRA, train, test\n",
    "from data_loader_clinical import RawDataLoader\n",
    "from evaluation import Evaluation\n",
    "from utils import *\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6ffafa-8a73-4ed9-ad63-1ccc0f33e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:207: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clinical_df['Age'].fillna(clinical_df['Age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the batch size for training\n",
    "batch_size = 64\n",
    "\n",
    "# Step 2: Instantiate the combined model\n",
    "ae_latent_dim = 50\n",
    "num_epochs = 25\n",
    "\n",
    "# Define the path to the clinical data file\n",
    "clinical_file_path = 'C:/Users/camil/IMAG/DeepDRA/clinical/matched_cell_lines_annotations.tsv'\n",
    "\n",
    "# Load the clinical dataset\n",
    "clinical_df = RawDataLoader.load_clinical_data(clinical_file_path)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_clinical_train, x_clinical_test = train_test_split(clinical_df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "clinical_input_dim = x_clinical_train.shape[1]\n",
    "\n",
    "def train_DeepDRA(x_cell_train, x_cell_test, x_drug_train, x_drug_test, x_clinical_train, x_clinical_test, y_train, y_test, cell_sizes, drug_sizes, device):\n",
    "    \"\"\"\n",
    "\n",
    "    Train and evaluate the DeepDRA model.\n",
    "\n",
    "    Parameters:\n",
    "    - X_cell_train (pd.DataFrame): Training data for the cell modality.\n",
    "    - X_cell_test (pd.DataFrame): Test data for the cell modality.\n",
    "    - X_drug_train (pd.DataFrame): Training data for the drug modality.\n",
    "    - X_drug_test (pd.DataFrame): Test data for the drug modality.\n",
    "    - X_clinical_train (pd.DataFrame): Clinical data corresponding to training samples.\n",
    "    - y_train (array-like): Training labels.\n",
    "    - y_test (array-like): Test labels.\n",
    "    - cell_sizes (list): Sizes of the cell modality features.\n",
    "    - drug_sizes (list): Sizes of the drug modality features.\n",
    "    - device: PyTorch device.\n",
    "\n",
    "    Returns:\n",
    "    - result: Evaluation result on the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    model = DeepDRA(cell_sizes, drug_sizes, clinical_input_dim, ae_latent_dim, ae_latent_dim)\n",
    "    model= model.to(device)\n",
    "\n",
    "    print(\"x_cell_train.shape:\", x_cell_train.shape)\n",
    "    print(\"x_drug_train.shape:\", x_drug_train.shape)\n",
    "    print(\"x_clinical_train.shape:\", x_clinical_train.shape)\n",
    "    print(\"y_train.shape:\", pd.Series(y_train).shape)\n",
    "\n",
    "    # Step 3: Convert your training data to PyTorch tensors\n",
    "    x_cell_train_tensor = torch.Tensor(x_cell_train.values)\n",
    "    x_drug_train_tensor = torch.Tensor(x_drug_train.values)\n",
    "    x_clinical_train_tensor = torch.Tensor(x_clinical_train.values)\n",
    "\n",
    "\n",
    "    # Normaliser les tenseurs des modalités cell et drug \n",
    "    x_cell_train_tensor = torch.nn.functional.normalize(x_cell_train_tensor, dim=0)\n",
    "    x_drug_train_tensor = torch.nn.functional.normalize(x_drug_train_tensor, dim=0)\n",
    "    y_train_tensor = torch.Tensor(y_train)\n",
    "    \n",
    "    y_train_tensor = y_train_tensor.unsqueeze(1)\n",
    "\n",
    "    # Compute class weights\n",
    "    classes = np.array([0, 1])  # Assuming binary classification\n",
    "    class_weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=classes, y=y_train),\n",
    "                                 dtype=torch.float32)\n",
    "\n",
    "    x_cell_train_tensor, x_cell_val_tensor, x_drug_train_tensor, x_drug_val_tensor, x_clinical_train_tensor, x_clinical_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "        x_cell_train_tensor, x_drug_train_tensor, x_clinical_train_tensor, y_train_tensor, test_size=0.1,\n",
    "        random_state=RANDOM_SEED,\n",
    "        shuffle=True)\n",
    "\n",
    "    # Step 4: Create a TensorDataset with the input features and target labels\n",
    "    train_dataset = TensorDataset(x_cell_train_tensor.to(device), x_drug_train_tensor.to(device), x_clinical_train_tensor.to(device), y_train_tensor.to(device))\n",
    "    val_dataset = TensorDataset(x_cell_val_tensor.to(device), x_drug_val_tensor.to(device), x_clinical_val_tensor.to(device), y_val_tensor.to(device))\n",
    "    \n",
    "    # Step 5: Create the train_loader and val_loader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Step 6: Train the model\n",
    "    train(model, train_loader, val_loader, num_epochs,class_weights)\n",
    "\n",
    "    # Step 7: Save the trained model\n",
    "    torch.save(model, 'DeepDRA.pth')\n",
    "\n",
    "    # Step 8: Load the saved model\n",
    "    model = torch.load('DeepDRA.pth', weights_only = False)\n",
    "\n",
    "    # Step 9: Convert your test data to PyTorch tensors\n",
    "    x_cell_test_tensor = torch.Tensor(x_cell_test.values)\n",
    "    x_drug_test_tensor = torch.Tensor(x_drug_test.values)\n",
    "    x_clinical_test_tensor = torch.Tensor(x_clinical_test.values)\n",
    "    y_test_tensor = torch.Tensor(y_test).to(device)\n",
    "\n",
    "    # normalize data\n",
    "    x_cell_test_tensor = torch.nn.functional.normalize(x_cell_test_tensor, dim=0).to(device)\n",
    "    x_drug_test_tensor = torch.nn.functional.normalize(x_drug_test_tensor, dim=0).to(device)\n",
    "\n",
    "    # Step 10: Create a TensorDataset with the input features and target labels for testing\n",
    "    test_dataset = TensorDataset(x_cell_test_tensor, x_drug_test_tensor, x_clinical_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(x_cell_test))\n",
    "\n",
    "    # Step 11: Test the model\n",
    "    return test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa48a7e-e10d-4a2f-bb6b-316ae53b057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! MANQUE DES MODIF DANS CETTE DEF POUR QUE CV_TRAIN INTÈGRE LES DONNÉES CLINIQUES !!! \n",
    "\n",
    "def cv_train(x_cell_train, x_drug_train, y_train, cell_sizes,\n",
    "                                    drug_sizes, device, k=5, ):\n",
    "\n",
    "\n",
    "    splits = KFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
    "    history = {'AUC': [], 'AUPRC': [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 score\": []}\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(x_cell_train)))):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        test_sampler = SubsetRandomSampler(val_idx)\n",
    "        model = DeepDRA(cell_sizes, drug_sizes, ae_latent_dim, ae_latent_dim)\n",
    "        # Convert your training data to PyTorch tensors\n",
    "        x_cell_train_tensor = torch.Tensor(x_cell_train.values)\n",
    "        x_drug_train_tensor = torch.Tensor(x_drug_train.values)\n",
    "        x_clinical_train_tensor = torch.Tensor(x_clinical_train.values)\n",
    "\n",
    "        y_train_tensor = torch.Tensor(y_train)\n",
    "        y_train_tensor = y_train_tensor.unsqueeze(1)\n",
    "\n",
    "        # Compute class weights\n",
    "        classes = [0, 1]  # Assuming binary classification\n",
    "        class_weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=classes, y=y_train),\n",
    "                                     dtype=torch.float32)\n",
    "\n",
    "        # Create a TensorDataset with the input features and target labels\n",
    "        train_dataset = TensorDataset(x_cell_train_tensor, x_drug_train_tensor, x_clinical_train_tensor, y_train_tensor)\n",
    "\n",
    "        # Create the train_loader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        # Train the model\n",
    "        train(model, train_loader,train_loader, num_epochs, class_weights)\n",
    "\n",
    "\n",
    "        # Create a TensorDataset with the input features and target labels\n",
    "        test_loader = DataLoader(train_dataset, batch_size=len(x_cell_train), sampler=test_sampler)\n",
    "\n",
    "        # Test the model\n",
    "        results = test(model, test_loader)\n",
    "\n",
    "        # Step 10: Add results to the history dictionary\n",
    "        Evaluation.add_results(history, results)\n",
    "\n",
    "\n",
    "    return Evaluation.show_final_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3057f947-e75b-4b7f-91f0-4f9b0de0b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Raw Data Files...:   0%|                                                                 | 0/5 [00:00<?, ?it/s]C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:143: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  if df.index.is_numeric():\n",
      "Reading Raw Data Files...:  40%|██████████████████████▊                                  | 2/5 [00:10<00:16,  5.35s/it]C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:143: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  if df.index.is_numeric():\n",
      "Reading Raw Data Files...: 100%|█████████████████████████████████████████████████████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Reading Raw Data Files...:   0%|                                                                 | 0/8 [00:00<?, ?it/s]C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:143: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  if df.index.is_numeric():\n",
      "C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:143: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  if df.index.is_numeric():\n",
      "Reading Raw Data Files...: 100%|█████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "sensitive train data len: 2690\n",
      "resistance train data len: 3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\IMAG\\DeepDRA\\data_loader_clinical.py:207: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clinical_df['Age'].fillna(clinical_df['Age'].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cell_train.shape: (5380, 36892)\n",
      "x_drug_train.shape: (5380, 4257)\n",
      "x_clinical_train.shape: (5380, 343)\n",
      "Run 0\n",
      "x_cell_train.shape: (4304, 36892)\n",
      "x_drug_train.shape: (4304, 4257)\n",
      "x_clinical_train.shape: (4304, 343)\n",
      "y_train.shape: (4304,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.4612, Val Loss: 0.0291, Train Accuracy: 0.8327, Val Accuracy: 0.9118\n",
      "Epoch [2/25], Train Loss: 0.2186, Val Loss: 0.0379, Train Accuracy: 0.9174, Val Accuracy: 0.9234\n",
      "Epoch [3/25], Train Loss: 0.1580, Val Loss: 0.0324, Train Accuracy: 0.9398, Val Accuracy: 0.9304\n",
      "Epoch [4/25], Train Loss: 0.1227, Val Loss: 0.0135, Train Accuracy: 0.9579, Val Accuracy: 0.9002\n",
      "Epoch [5/25], Train Loss: 0.1084, Val Loss: 0.0159, Train Accuracy: 0.9608, Val Accuracy: 0.9165\n",
      "Epoch [6/25], Train Loss: 0.0987, Val Loss: 0.0160, Train Accuracy: 0.9620, Val Accuracy: 0.9142\n",
      "Epoch [7/25], Train Loss: 0.0984, Val Loss: 0.0138, Train Accuracy: 0.9672, Val Accuracy: 0.9165\n",
      "Epoch [8/25], Train Loss: 0.0935, Val Loss: 0.0177, Train Accuracy: 0.9680, Val Accuracy: 0.9281\n",
      "Epoch [9/25], Train Loss: 0.0949, Val Loss: 0.0486, Train Accuracy: 0.9664, Val Accuracy: 0.9281\n",
      "Epoch [10/25], Train Loss: 0.0949, Val Loss: 0.0206, Train Accuracy: 0.9682, Val Accuracy: 0.9327\n",
      "Epoch [11/25], Train Loss: 0.0821, Val Loss: 0.0123, Train Accuracy: 0.9708, Val Accuracy: 0.9211\n",
      "Epoch [12/25], Train Loss: 0.0812, Val Loss: 0.0385, Train Accuracy: 0.9706, Val Accuracy: 0.9281\n",
      "Epoch [13/25], Train Loss: 0.0773, Val Loss: 0.0284, Train Accuracy: 0.9724, Val Accuracy: 0.9234\n",
      "Epoch [14/25], Train Loss: 0.0781, Val Loss: 0.0377, Train Accuracy: 0.9690, Val Accuracy: 0.9234\n",
      "Epoch [15/25], Train Loss: 0.0755, Val Loss: 0.0472, Train Accuracy: 0.9719, Val Accuracy: 0.9165\n",
      "Epoch [16/25], Train Loss: 0.0795, Val Loss: 0.0156, Train Accuracy: 0.9700, Val Accuracy: 0.9281\n",
      "Epoch [17/25], Train Loss: 0.0778, Val Loss: 0.0214, Train Accuracy: 0.9713, Val Accuracy: 0.9049\n",
      "Epoch [18/25], Train Loss: 0.0721, Val Loss: 0.0241, Train Accuracy: 0.9734, Val Accuracy: 0.9165\n",
      "Epoch [19/25], Train Loss: 0.0761, Val Loss: 0.0330, Train Accuracy: 0.9675, Val Accuracy: 0.9188\n",
      "Epoch [20/25], Train Loss: 0.0649, Val Loss: 0.0878, Train Accuracy: 0.9757, Val Accuracy: 0.9234\n",
      "Epoch [21/25], Train Loss: 0.0669, Val Loss: 0.0718, Train Accuracy: 0.9716, Val Accuracy: 0.9258\n",
      "Epoch [22/25], Train Loss: 0.0627, Val Loss: 0.0267, Train Accuracy: 0.9721, Val Accuracy: 0.9211\n",
      "Epoch [23/25], Train Loss: 0.0587, Val Loss: 0.0408, Train Accuracy: 0.9757, Val Accuracy: 0.9211\n",
      "Epoch [24/25], Train Loss: 0.0569, Val Loss: 0.0862, Train Accuracy: 0.9747, Val Accuracy: 0.9234\n",
      "Epoch [25/25], Train Loss: 0.0530, Val Loss: 0.0265, Train Accuracy: 0.9773, Val Accuracy: 0.9002\n",
      "Confusion matrix:\n",
      "[[495  54]\n",
      " [ 22 505]]\n",
      "Accuracy: 0.929, Precision: 0.902, Recall: 0.957, F1 score: 0.929, AUC: 0.978, ,AUPRC: 0.982\n",
      "Run 1\n",
      "x_cell_train.shape: (4304, 36892)\n",
      "x_drug_train.shape: (4304, 4257)\n",
      "x_clinical_train.shape: (4304, 343)\n",
      "y_train.shape: (4304,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.4636, Val Loss: 0.0351, Train Accuracy: 0.7888, Val Accuracy: 0.9118\n",
      "Epoch [2/25], Train Loss: 0.2097, Val Loss: 0.0147, Train Accuracy: 0.9169, Val Accuracy: 0.9281\n",
      "Epoch [3/25], Train Loss: 0.1540, Val Loss: 0.0262, Train Accuracy: 0.9416, Val Accuracy: 0.9234\n",
      "Epoch [4/25], Train Loss: 0.1252, Val Loss: 0.0227, Train Accuracy: 0.9527, Val Accuracy: 0.9258\n",
      "Epoch [5/25], Train Loss: 0.1189, Val Loss: 0.0263, Train Accuracy: 0.9579, Val Accuracy: 0.9281\n",
      "Epoch [6/25], Train Loss: 0.1039, Val Loss: 0.0332, Train Accuracy: 0.9641, Val Accuracy: 0.9211\n",
      "Epoch [7/25], Train Loss: 0.0986, Val Loss: 0.0341, Train Accuracy: 0.9644, Val Accuracy: 0.9118\n",
      "Epoch [8/25], Train Loss: 0.0949, Val Loss: 0.0301, Train Accuracy: 0.9659, Val Accuracy: 0.9188\n",
      "Epoch [9/25], Train Loss: 0.0943, Val Loss: 0.0262, Train Accuracy: 0.9672, Val Accuracy: 0.9188\n",
      "Epoch [10/25], Train Loss: 0.0892, Val Loss: 0.0171, Train Accuracy: 0.9685, Val Accuracy: 0.9350\n",
      "Epoch [11/25], Train Loss: 0.0931, Val Loss: 0.0247, Train Accuracy: 0.9672, Val Accuracy: 0.9258\n",
      "Epoch [12/25], Train Loss: 0.0861, Val Loss: 0.0097, Train Accuracy: 0.9688, Val Accuracy: 0.9211\n",
      "Epoch [13/25], Train Loss: 0.0879, Val Loss: 0.0313, Train Accuracy: 0.9685, Val Accuracy: 0.9258\n",
      "Epoch [14/25], Train Loss: 0.0895, Val Loss: 0.0269, Train Accuracy: 0.9682, Val Accuracy: 0.9304\n",
      "Epoch [15/25], Train Loss: 0.0839, Val Loss: 0.0472, Train Accuracy: 0.9700, Val Accuracy: 0.9258\n",
      "Epoch [16/25], Train Loss: 0.0786, Val Loss: 0.0093, Train Accuracy: 0.9703, Val Accuracy: 0.9327\n",
      "Epoch [17/25], Train Loss: 0.0742, Val Loss: 0.0448, Train Accuracy: 0.9695, Val Accuracy: 0.9165\n",
      "Epoch [18/25], Train Loss: 0.0780, Val Loss: 0.0437, Train Accuracy: 0.9695, Val Accuracy: 0.9258\n",
      "Epoch [19/25], Train Loss: 0.0679, Val Loss: 0.0548, Train Accuracy: 0.9724, Val Accuracy: 0.9234\n",
      "Epoch [20/25], Train Loss: 0.0674, Val Loss: 0.0020, Train Accuracy: 0.9695, Val Accuracy: 0.9072\n",
      "Epoch [21/25], Train Loss: 0.0620, Val Loss: 0.0304, Train Accuracy: 0.9724, Val Accuracy: 0.9281\n",
      "Epoch [22/25], Train Loss: 0.0610, Val Loss: 0.0441, Train Accuracy: 0.9726, Val Accuracy: 0.9281\n",
      "Epoch [23/25], Train Loss: 0.0598, Val Loss: 0.0477, Train Accuracy: 0.9734, Val Accuracy: 0.9258\n",
      "Epoch [24/25], Train Loss: 0.0544, Val Loss: 0.0478, Train Accuracy: 0.9752, Val Accuracy: 0.9234\n",
      "Epoch [25/25], Train Loss: 0.0511, Val Loss: 0.0465, Train Accuracy: 0.9762, Val Accuracy: 0.9304\n",
      "Confusion matrix:\n",
      "[[521  28]\n",
      " [ 32 495]]\n",
      "Accuracy: 0.944, Precision: 0.949, Recall: 0.942, F1 score: 0.946, AUC: 0.979, ,AUPRC: 0.983\n",
      "Run 2\n",
      "x_cell_train.shape: (4304, 36892)\n",
      "x_drug_train.shape: (4304, 4257)\n",
      "x_clinical_train.shape: (4304, 343)\n",
      "y_train.shape: (4304,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.4681, Val Loss: 0.0235, Train Accuracy: 0.7983, Val Accuracy: 0.9095\n",
      "Epoch [2/25], Train Loss: 0.2187, Val Loss: 0.0140, Train Accuracy: 0.9153, Val Accuracy: 0.9234\n",
      "Epoch [3/25], Train Loss: 0.1638, Val Loss: 0.0198, Train Accuracy: 0.9373, Val Accuracy: 0.9165\n",
      "Epoch [4/25], Train Loss: 0.1250, Val Loss: 0.0243, Train Accuracy: 0.9569, Val Accuracy: 0.9258\n",
      "Epoch [5/25], Train Loss: 0.1136, Val Loss: 0.0211, Train Accuracy: 0.9605, Val Accuracy: 0.9234\n",
      "Epoch [6/25], Train Loss: 0.1069, Val Loss: 0.0148, Train Accuracy: 0.9618, Val Accuracy: 0.9002\n",
      "Epoch [7/25], Train Loss: 0.1048, Val Loss: 0.0299, Train Accuracy: 0.9651, Val Accuracy: 0.9281\n",
      "Epoch [8/25], Train Loss: 0.1038, Val Loss: 0.0182, Train Accuracy: 0.9620, Val Accuracy: 0.9165\n",
      "Epoch [9/25], Train Loss: 0.0960, Val Loss: 0.0363, Train Accuracy: 0.9639, Val Accuracy: 0.9258\n",
      "Epoch [10/25], Train Loss: 0.0897, Val Loss: 0.0405, Train Accuracy: 0.9690, Val Accuracy: 0.9258\n",
      "Epoch [11/25], Train Loss: 0.0878, Val Loss: 0.0391, Train Accuracy: 0.9700, Val Accuracy: 0.9234\n",
      "Epoch [12/25], Train Loss: 0.0868, Val Loss: 0.0306, Train Accuracy: 0.9690, Val Accuracy: 0.9281\n",
      "Epoch [13/25], Train Loss: 0.0818, Val Loss: 0.0169, Train Accuracy: 0.9708, Val Accuracy: 0.9327\n",
      "Epoch [14/25], Train Loss: 0.0805, Val Loss: 0.0465, Train Accuracy: 0.9688, Val Accuracy: 0.9142\n",
      "Epoch [15/25], Train Loss: 0.0765, Val Loss: 0.0427, Train Accuracy: 0.9698, Val Accuracy: 0.9350\n",
      "Epoch [16/25], Train Loss: 0.0747, Val Loss: 0.0288, Train Accuracy: 0.9724, Val Accuracy: 0.9049\n",
      "Epoch [17/25], Train Loss: 0.0717, Val Loss: 0.0475, Train Accuracy: 0.9713, Val Accuracy: 0.9188\n",
      "Epoch [18/25], Train Loss: 0.0696, Val Loss: 0.0076, Train Accuracy: 0.9693, Val Accuracy: 0.9165\n",
      "Epoch [19/25], Train Loss: 0.0680, Val Loss: 0.0384, Train Accuracy: 0.9703, Val Accuracy: 0.9350\n",
      "Epoch [20/25], Train Loss: 0.0625, Val Loss: 0.0050, Train Accuracy: 0.9742, Val Accuracy: 0.9327\n",
      "Epoch [21/25], Train Loss: 0.0588, Val Loss: 0.0397, Train Accuracy: 0.9731, Val Accuracy: 0.9327\n",
      "Epoch [22/25], Train Loss: 0.0573, Val Loss: 0.0197, Train Accuracy: 0.9747, Val Accuracy: 0.9072\n",
      "Epoch [23/25], Train Loss: 0.0543, Val Loss: 0.0812, Train Accuracy: 0.9768, Val Accuracy: 0.9304\n",
      "Epoch [24/25], Train Loss: 0.0569, Val Loss: 0.0515, Train Accuracy: 0.9752, Val Accuracy: 0.9304\n",
      "Epoch [25/25], Train Loss: 0.0516, Val Loss: 0.0796, Train Accuracy: 0.9773, Val Accuracy: 0.9304\n",
      "Confusion matrix:\n",
      "[[517  32]\n",
      " [ 28 499]]\n",
      "Accuracy: 0.944, Precision: 0.942, Recall: 0.949, F1 score: 0.945, AUC: 0.980, ,AUPRC: 0.983\n",
      "Final Results:\n",
      "AVG: Accuracy: 0.939, Precision: 0.931, Recall: 0.949, F1 score: 0.940, AUC: 0.979, ,AUPRC: 0.983\n",
      " Average AUC: 0.979 \t Average AUPRC: 0.983 \t Std AUPRC: 0.001\n"
     ]
    }
   ],
   "source": [
    "def run(k, is_test=False ):\n",
    "    \"\"\"\n",
    "    Run the training and evaluation process k times.\n",
    "\n",
    "    Parameters:\n",
    "    - k (int): Number of times to run the process.\n",
    "    - is_test (bool): If True, run on test data; otherwise, perform train-validation split.\n",
    "\n",
    "    Returns:\n",
    "    - history (dict): Dictionary containing evaluation metrics for each run.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    # Step 1: Initialize a dictionary to store evaluation metrics\n",
    "    history = {'AUC': [], 'AUPRC': [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 score\": []}\n",
    "    \n",
    "    # Step 2: Load training data\n",
    "    train_data, train_drug_screen = RawDataLoader.load_data(data_modalities=DATA_MODALITIES,\n",
    "                                                            raw_file_directory=CCLE_RAW_DATA_FOLDER,\n",
    "                                                            screen_file_directory=CCLE_SCREENING_DATA_FOLDER,\n",
    "                                                            sep=\"\\t\")\n",
    "    \n",
    "    # Step 3: Load test data if applicable\n",
    "    if is_test:\n",
    "        test_data, test_drug_screen = RawDataLoader.load_data(data_modalities=DATA_MODALITIES,\n",
    "                                                              raw_file_directory=TCGA_DATA_FOLDER,\n",
    "                                                              screen_file_directory=TCGA_SCREENING_DATA,\n",
    "                                                              sep=\"\\t\")\n",
    "        \n",
    "        train_data, test_data = RawDataLoader.data_features_intersect(train_data, test_data)\n",
    "\n",
    "        #common_columns = list(set(train_drug_screen.columns) & set(test_drug_screen.columns))\n",
    "        \n",
    "        #train_drug_screen.drop(common_columns[1:100], axis=1, inplace=True)\n",
    "        #test_drug_screen = test_drug_screen[common_columns[1:100]]\n",
    "    \n",
    "    # Step 4: Prepare input data for training\n",
    "    x_cell_train, x_drug_train, y_train, cell_sizes, drug_sizes = RawDataLoader.prepare_input_data(train_data,\n",
    "                                                                                                   train_drug_screen)\n",
    "\n",
    "    # Chargez le fichier des annotations cliniques\n",
    "    clinical_data = RawDataLoader.load_clinical_data('C:/Users/camil/IMAG/DeepDRA/clinical/matched_cell_lines_annotations.tsv', index_col='Cell_Line')\n",
    "    \n",
    "    # 1. Extraire le nom de la lignée cellulaire depuis l'index de x_cell_train (format \"(CellLine,Drug)\")\n",
    "    extracted_names = x_cell_train.index.str.extract(r'\\(([^,]+),')[0]\n",
    "    \n",
    "    # 2. Créer un masque pour retenir uniquement les échantillons dont le nom (extrait) est présent dans clinical_data\n",
    "    mask = extracted_names.isin(clinical_data.index)\n",
    "    \n",
    "    # 3. Appliquer ce masque aux DataFrames omiques en utilisant mask.values pour l'indexation par position\n",
    "    x_cell_train = x_cell_train[mask.values]\n",
    "    x_drug_train = x_drug_train[mask.values]\n",
    "    # Mettre à jour les index pour que chaque paire cell-drug reçoive le nom de la lignée\n",
    "    x_cell_train.index = extracted_names[mask]\n",
    "    x_drug_train.index = extracted_names[mask]\n",
    "    # Pour y_train, convertir en Series et utiliser mask.values\n",
    "    y_train = pd.Series(y_train, index=extracted_names.index)[mask.values].values\n",
    "\n",
    "\n",
    "    if is_test:\n",
    "        x_cell_test, x_drug_test, y_test, cell_sizes, drug_sizes = RawDataLoader.prepare_input_data(test_data,\n",
    "                                                                                                    test_drug_screen)\n",
    "    \n",
    "    # 4. Récupérer les données cliniques pour chaque lignée cellulaire\n",
    "    clinical_x = clinical_data.loc[x_cell_train.index]\n",
    "    \n",
    "    rus = RandomUnderSampler(sampling_strategy=\"majority\", random_state=RANDOM_SEED)\n",
    "    dataset = pd.concat([x_cell_train, x_drug_train, clinical_x], axis=1)\n",
    "    dataset.index = x_cell_train.index\n",
    "    dataset, y_train = rus.fit_resample(dataset, y_train)\n",
    "\n",
    "    x_cell_train = dataset.iloc[:, :sum(cell_sizes)]\n",
    "    x_drug_train = dataset.iloc[:, sum(cell_sizes):sum(cell_sizes) + sum(drug_sizes)]\n",
    "    x_clinical_train = dataset.iloc[:, sum(cell_sizes) + sum(drug_sizes):]\n",
    "\n",
    "    print(\"x_cell_train.shape:\", x_cell_train.shape)\n",
    "    print(\"x_drug_train.shape:\", x_drug_train.shape)\n",
    "    print(\"x_clinical_train.shape:\", x_clinical_train.shape)\n",
    "\n",
    "    \n",
    "    # Step 5: Loop over k runs\n",
    "    for i in range(k):\n",
    "        print('Run {}'.format(i))\n",
    "\n",
    "        # Step 6: If is_test is True, perform random under-sampling on the training data\n",
    "        if is_test:\n",
    "\n",
    "            # Step 7: Train and evaluate the DeepDRA model on test data\n",
    "            results = train_DeepDRA(x_cell_train, x_cell_test, x_drug_train, x_drug_test, x_clinical_train, x_clinical_test, y_train, y_test, cell_sizes,\n",
    "                                    drug_sizes, device)\n",
    "\n",
    "        else:\n",
    "            # Step 8: Split the data into training and validation sets\n",
    "            x_cell_train_split, x_cell_val, x_drug_train_split, x_drug_val, x_clinical_train_split, x_clinical_val, y_train_split, y_val = train_test_split(x_cell_train,\n",
    "                                                                                                      x_drug_train, x_clinical_train, y_train,\n",
    "                                                                                                      test_size=0.2,\n",
    "                                                                                                      random_state=RANDOM_SEED,\n",
    "                                                                                                      shuffle=True)\n",
    "            # Step 9: Train and evaluate the DeepDRA model on the split data\n",
    "            results = train_DeepDRA(x_cell_train_split, x_cell_val, x_drug_train_split, x_drug_val, x_clinical_train_split, x_clinical_val, y_train_split, y_val, cell_sizes,\n",
    "                                     drug_sizes, device)\n",
    "\n",
    "            #results = cv_train(x_cell_train, x_drug_train, y_train, cell_sizes, drug_sizes, device, k=5)    # ! PAS ENCORE OPERATIONNEL !\n",
    "\n",
    "        # Step 10: Add results to the history dictionary\n",
    "        Evaluation.add_results(history, results)\n",
    "\n",
    "    # Step 11: Display final results\n",
    "    Evaluation.show_final_results(history)\n",
    "    return history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    run(3, is_test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
